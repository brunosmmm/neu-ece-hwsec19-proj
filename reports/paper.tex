\documentclass[10pt,conference]{IEEEtran}
\usepackage[dvipsnames]{xcolor}
\usepackage{standalone}
\usepackage{tikz}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{booktabs}
\usepackage{tabu}
\usepackage[letterpaper]{geometry}
\usepackage[colorlinks]{hyperref}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2cm,rmargin=2cm,columnsep=0.8cm}
\usetikzlibrary{positioning, calc, shapes, fit, backgrounds, patterns}

\title{\textbf{Hardware accelerator coupling in heterogeneous systems: an evaluation in the
    security domain}}
\author{Bruno Morais \texttt{<soutomaiormunizmo.b@husky.neu.edu>}}
\date{}

\begin{document}

\maketitle

\begin{abstract}
  Hardware accelerators (HWACCs) have driven performance gains for
  domain specific applications which leverage highly optimized computation
  cores. However, the traditional accelerator access topology as an add-on to
  general purpose processors through shared memory space/bus, reveals performance
  issues as the number of HWACCs grow and systems become
  communication-bound.
  On the other hand, efficient development and research of HWACCs
  that are closer to a general purpose processor's datapath is seen as a
  prohibitive task due to the required microarchitecture knowledge and lack of
  tools to explore the design space. This has in turn hindered the exploration of
  such architectures for gains in either performance or security spectrums.
  RISC-V projects made available in the last few years provide a framework that
  greatly eases microarchitecture research, enabling further experimentation
  into security and performance aspects for heterogeneous platforms.
  This work uses a customized RISC-V SoC to explore performance trade-offs
  between different HWACC topologies (in-datapath, memory-mapped) for embedded
  systems in the security domain by implementing an IP core for cryptographic
  primitive acceleration. We also show a hybrid accelerator topology for
  acceleration and/or secure memory storage which offers a speedup of 6x compared to a
  pure software implementation.

\end{abstract}

\section{Introduction}

The demand for power-efficient computing, specially on edge and/or embedded
devices has continuously driven the development of hardware accelerators
(HWACCs) to meet these power requirements. General-purpose computing units alone
are too flexible and cannot achieve the same parallelism as a specialized
accelerator. The growing complexity of algorithms, specially with the advent of
widespread machine learning and security needs such as authentication, integrity
verification and privacy, has pushed the boundaries of embedded systems,
dramatically increasing the number of accelerators present in sophisticated
embedded SoCs.

With the number of HWACCs rapidly increasing, the use of typical memory mapped HWACC,
which shares the memory bus of a general purpose CPU creates bottlenecks~\cite{TSS},
specially for certain classes of applications, for instance streaming-based
applications, where communication between HWACCs (function compositions) is a requirement.
Figure~\ref{fig:loosely} shows the typical memory-mapped HWACC, also called a
\textit{loosely-coupled} HWACC.

\begin{figure}
  \centering
  \include{media/loosely_acc}
  \caption{Loosely-coupled HWACCs: typical memory mapped HWACC usage in a heterogenous architecture.}
  \label{fig:loosely}
\end{figure}

In constrast with the \textit{loosely-coupled} accelerator which is external to
the CPU datapath, an alternative topology is to bring the HWACC much closer, and
effectively into the CPU datapath itself. Those are called
\textit{tightly-coupled} HWACCs. Essentially, in this configuration, the HWACC
can be seen as one of the CPU's functional units, dedicated to a certain
specific task. Figure~\ref{fig:tightly} shows a simplified CPU datapath with
tightly-coupled accelerators.

While it is relatively straightforward to design accelerators and perform research using
loosely-coupled accelerators by deploying them in FPGAs, for instance, research
into tightly-coupled HWACCs has been historically prohibitive due to the need to
have an easily modifiable processor implementation and all the necessary
supporting tools such as compiler toolchain, simulators and a synthesis enabled
design. The RISC-V project and its community have fostered the development of
such a system, which is open source and user friendly, enabling much easier
research of such a topology.

Tightly-coupled accelerators are invaluable from a security perspective, not
only to accelerate cryptographic functions but also to enable secure data
storage. The main contribution of this work is the implementation of a HWACC
that accelerates the Simon cipher and an analysis of the speedup provided by
different couplings. We also show a hybrid tightly-coupled accelerator which has
access to the on-chip coherent memory hierarchy and enables secure data storage
and retrieval to/from main memory.

\begin{figure}
  \centering
  \resizebox{0.3\textwidth}{!}{
    \begin{minipage}{0.5\textwidth}
      \centering
      \include{media/tightly_acc}
    \end{minipage}
  }
  \caption{Tightly-coupled HWACCs: accelerator is moved into CPU datapath,
    operating similarly to microarchitectural Functional Units (FUs).}
  \label{fig:tightly}
\end{figure}

\section{Related work}

\subsection{Hardware accelerator coupling in heterogeneous systems}
The usage of different couplings (tightly/loosely coupled) leads to mixed
results depending on the domain of the application. Typical usage of HWACCs fall
within the loosely-coupled category, which pays little attention to interaction
with on-chip components such as caches~\cite{tightLoose}.

There is potential gain by moving accelerators into the CPU datapath and
enabling leveraging the memory hierarchy to increase speedup. This incurs in
more development costs, as discussed before when compared to loosely-coupled
accelerators, which are more easily abstracted and do not need extensive
modifications to the toolchain.

\subsection{RISC-V cryptographic extensions}
The RISC-V community has formed a group to specify ISA extensions for
cryptographic primitives~\cite{RiscVCrypto}. The approach is similar to Intel's
AES-NI~\cite{AESNI}, and is expected to support at least AES and SHA-2. These
type of accelerators are tightly-coupled accelerators directly controlled by
software instructions.

There is also some independent work showcasing the implementation of accelerated
cryptographic functions by means of instruction set extensions by the University
of Bristol~\cite{xcrypto}. The XCrypto is part of a larger project and
implements AES, SHA-2 and SHA-3.

\section{Background}


\subsection{Embedded security: lightweight ciphers}

Industry standard ciphers such as AES might impose too much of a burden on deeply
embedded, low power systems that need the ability to communicate securely over
an unsecured channel. Thus, different organizations have hosted competitions to
foster the development of lightweight ciphers, targeting both resource-limited
software and hardware implementations.

In this evaluation, it is assumed that the object of study is such a system,
with strict area and power limitations. The Simon~\cite{Beaulieu2015} cipher family is chosen as a
lightweight cipher; it is a hardware-optimized cipher family developed by the
NSA. Although faced with controversies due to polarized views towards the
authors, it is an ISO standardized cipher.

The Simon family of ciphers offers different possibilities for both block and
key sizes. In all cases, both the round and key expansion functions make use
only of bitwise \texttt{XOR}, \texttt{AND}, and left and right circular shifts.
Figure~\ref{fig:simonround} shows the Feistel stepping of its round function.

\begin{figure}
  \centering
  \include{media/simonround}
  \caption{Simon's round function Feistel stepping. \textbf{S\textsuperscript{j}} are
    circular left shifts by j bits; \textbf{\&} is a bitwise \texttt{AND}
    operation and $\oplus$ are bitwise \texttt{XOR} operations.}
  \label{fig:simonround}
\end{figure}

The number of necessary rounds is determined by the configuration of the cipher.
In this work we explore only the Simon64/128 and Simon128/128 configurations,
which require a number of 44 and 68 rounds per block, respectively.
In the nomenclature Simon\textbf{N}/\textbf{M}, \textbf{N} is the block size and
\textbf{M} is the key size in bits.

\subsection{RISC-V ecosystem}

The RISC-V ecosystem is rapidly growing, with many different implementations of
the RISC-V ISA standard currently available online. The complete GNU toolchain
is also available for the architecture and its standard extensions.

There are several alternatives in order to assemble a complete System on Chip
(SoC) for experimentation or synthesis purposes. Several different vendors /
open source community-provided designs can be used to kickstart development.

To assemble an entire SoC for cycle-accurate simulation, UC Berkeley's Chipyard~\cite{Chipyard}
is chosen. Specifically, technologies used include:

\subsubsection{RISC-V cores}

There is already a variety of readily usable RISC-V cores out in the wild. To
study different HWACC topologies, UC Berkeley's implementations are chosen; we
select Rocket (in-order 5 stage pipeline, riscv64) and Berkeley out-of-order
machine (BOOM).

\subsubsection{RoCC interface}

The RoCC interface is an interface developed for the Rocket RISC-V core that
allows easy integration of HWACCs, effectively enabling the construction of
tightly-coupled accelerators. This interface is also supported in UC Berkeley's
BOOM implementation. In this paper, the terms tightly-coupled accelerator and
RoCC accelerator are used interchangeably when talking about the specific
implementations related to evaluation and results.

The RISC-V ISA specifies 4 different opcodes, \texttt{custom0-3} which are used for passing data
into and back the RoCC interface; with this mechanism, the HWACC is receives the
contents of up to two CPU registers and optionally passes back a word to be stored in any of
the CPU's registers as a result of the operation.

\begin{figure}
  \centering
  \resizebox{0.45\textwidth}{!}{
    \begin{minipage}{0.5\textwidth}
      \centering
      \include{media/hybrid_acc}
    \end{minipage}
  }
  \caption{Hybrid crypto HWACCs: \textbf{upper}: HWACC is directly accessible through CPU datapath and
    integrated with memory hierarchy; \textbf{lower}: two operation modes; I: batch
    background processing of memory region (CPU not taxed); II: cryptographic
    operation where plaintext is only visible inside CPU datapath.}
  \label{fig:hybrid}
\end{figure}

\section{The Hybrid Crypto Accelerator}

Going one step further than the two previously discussed topologies used for
accelerators, we present a slightly different hybrid approach which has
some interesting characteristics. Figure~\ref{fig:hybrid} shows the concept and
possible operation modes of the hybrid crypto accelerator.

The hybrid crypto accelerator is distinct from the tightly-coupled topology in
the way that it has a DMA port for direct access to the coherent memory
hierarchy. This allows the accelerator to directly request data to be loaded and
stored, enabling two different modes of operation. Note that due to the
architecture of the RoCC interface, the accelerator will have access to the
coherent memory hierarchy at the L2 cache level.

\subsection{Operation mode I: batch processing}

In this operation mode, specific instructions configure the accelerator to
batch perform encryption or decryption over a memory region. The accelerator
then proceeds to work while the CPU is left free for any other tasks that might
be waiting for CPU time.


\subsection{Operation mode II: cryptographic operation}

Differently from mode I, this mode allows for operation in the security domain,
isolating plaintext and ciphertext completely in the CPU datapath and memory.

In this mode, data is moved to/from memory by the CPU, through the accelerator,
which transparently encrypts or decrypts the data stored/loaded. Note that in
this mode, actual data (words) in the CPU datapath is passed in/out of the
accelerator, not control (load/store).

\section{Experimental setup}

In order to understand the area and performance trade-offs between the usage of
different system topologies, both a reference software implementation and an IP
core that performs the Simon cipher are implemented and tested on a RISC-V core.

The first step is to verify basic functionality by means of functional simulations.

\subsection{Functional simulation}

Functional simulation is accomplished with Spike~\cite{spike}, which is a RISC-V
instruction set simulator. Spike allows for execution of riscv64 binaries, and
also allows for implementation of C++ extensions that emulate the
functionalities of both memory-mapped peripherals and RoCC accelerators. Both
extensions are implemented to emulate functionality of different Simon
accelerators, and checked for result correctness against the reference software
implementation.


\subsection{Simon HWACCs}

After the functional simulations are performed with correct results, the Simon
cipher IP core was implemented in Chisel~\cite{chisel}. This was a necessary
choice since the infrastructure used to build the SoC to be evaluated is
completely built using Chisel.

The core Simon cipher functionality is implemented as the core IP and is
re-utilized to build three different accelerator types: memory-mapped I/O
(MMIO, loosely-coupled), RoCC (tightly-coupled and hybrid). In essence the the
accelerators are built by constructing wrappers around the common core.

The first two accelerators have similar functionality: the user must initialize the
accelerator by storing a key, at which point the acelerator core performs
necessary key expansion and waits for input data that is to be
encrypted/decrypted. Those accelerators support two different Simon widths:
Simon64/128 and Simon128/128.

The MMIO accelerator can operate in two different ways: i) automatic
operation --- ECB mode only, in which all necessary rounds are performed over a word until
completion of encryption/decryption process, or ii) interactive or single operation, where
software issues one round at a time, which enables software implementation of
CBC or other modes.

The tightly-coupled accelerator only operates interactively; that is, the
software manually issues an instruction that computes a round repetitively
until the complete process is done; encryption modes are thus
implemented in software.

The hybrid accelerator also needs to be initialized with a key. However, due to
development constraints, the accelerator only supports Simon64/128 in ECB mode.


\subsection{Full SoC simulation}

Chipyard is used to generate synthesizable Verilog for the
entire SoC, including RISC-V CPU core and accelerators under test. The tool also
contains the necessary scripts to produce a cycle-accurate simulation of the
SoC, compiled with Verilator. After configuration of the environment, the Simon
chisel implementation is integrated in the SoC.

In Chipyard the option of either building the SoC using in-order (Rocket) or
out-of-order (BOOM) cores is given to the user. SoCs are built using both
alternatives for evaluation.

\subsection{Synthesis metrics}

Unfortunately, while the output from Chipyard is indeed synthesizable Verilog,
no support for targeting FPGA boards is readily available. Instead, the focus of
the tool is to enable VLSI flows for taping out custom ASICs.

However, Chipyard shares much of common RISC-V infrastructure that is maintained
by the CHIPS Alliance, it is possible to modify other projects that also use the
same infrastructure, and do target FPGA boards to include our accelerators. This
flow is used mainly for area evaluation purposes and not fully concerned with
actually running code on an FPGA prototyping target. SiFive's Freedom Platform
dev kit is chosen for this task.

We generate a system that targets Digilent's Arty FPGA board, then use Xilinx
Vivado to perform synthesis and implementation and extract metrics.

\section{Evaluation results}

\subsection{Performance}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{media/ecb_speedup}
  \caption{Speedup using different accelerator configurations in ECB mode.
    Values are relative to the in-order pure software implementation.}
  \label{fig:ecbspeedup}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{media/cbc_speedup}
  \caption{Speedup using different accelerator configurations in CBC mode.}
  \label{fig:cbcspeedup}
\end{figure}

To evaluate performance, we consider the case where a plaintext block with a size of
1 kB is encrypted using different implementations of the Simon cipher, yielding
eight different benchmarks:

\begin{itemize}
\item Software only: ECB and CBC mode
\item MMIO accelerator, single: ECB and CBC mode
\item MMIO accelerator, automatic: ECB mode
\item Tightly-coupled accelerator: ECB and CBC mode
\item Hybrid accelerator: ECB mode
\end{itemize}

Usage of the MMIO accelerator in automatic mode highlights the characteristics
of a heterogeneous system that is computation-bound, whereas usage of it in the
single mode intends to model a communication-bound architecture.

The reference software implementation is used as a baseline,
Figures~\ref{fig:ecbspeedup},\ref{fig:cbcspeedup} show the relative speedup
(computed from the total cycle count for each of the benchmarks) of alternative
implementations using accelerators or a 2-way BOOM core for encryption in ECB
and CBC mode, respectively.

% TODO small interpretation paragraph here
The hybrid accelerator is significantly faster than all other implementations
tested. This is to be expected since the accelerator itself performs the memory
requests without intervention of the CPU, directly into the memory bus. The
MMIO accelerator in the automatic mode comes in as second fastest. This
is also to be expected in comparison with the RoCC accelerator for example,
since the latter is run in interactive mode, that is, the application code
issues each round sequentially and sequential rounds are not immediately
executed by the CPU, due to buffering and communication logic in the RoCC
adapter fabric, in contrast to the former where rounds occur immediately (next
clock cycle) one after the other. The MMIO accelerator in single mode greatly
suffers from the need to access the memory bus for each operation, ultimately
making it slower than software.

% superscalar also

Figure~\ref{fig:scatter} shows the relationship between number of instructions
retired by processor and total number of cycles for the benchmark to finish in
the in-order (rocket) core. Ultimately, the number of instructions retired is
correlated to code size; it is clear that for the accelerator configurations
that allow encryption in the CBC mode to be implemented, there is little
overhead incurred by the extra operations (XORs), which are carried out by
the CPU.


\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{media/scatter_results}
  \caption{Distribution of all benchmark results with respect to both total
    number of instructions retired by processor and total number of cycles
    required to complete operations.}
  \label{fig:scatter}
\end{figure}

\subsection{Area}

Synthesis and implementation are performed using Vivado. This is only done
once, for the MMIO accelerator, as the core implementation of Simon is shared
across all accelerators. Usage as reported by vivado is at 3119 LUTs and 2004
flip flops, which account for approximately 17\% and 19.5\% of the total design
(SoC) size. The target FPGA has a total of 20800 and 41600 LUTs and flip flops
available, respectively.

The somewhat large size of the accelerator design stems mainly from the
unoptimized key expansion function, which accounts for roughly 75\% and 83.5\%
of the flip flop and LUT usage for the entire accelerator. The round function
accounts for the rest of the usage.

\subsection{Power}

Estimated power consumption is also reported after synthesis and implementation
using Vivado. It is reported as 8mW for the simon accelerator alone --- the
entire SoC power consumption is estimated at 252 mW (HWACC accounts for $\approx$ 3\%).

As is the case for area, power the key expansion is also responsible for the
majority of power consumption, approximately 87.5\% of the total for the accelerator.

\subsection{Security implications}

It is of note that while this work implements a cryptographic primitive that can
be used in-hardware to enable acceleration of ciphers, it is a proof-of-concept
level, rudimentary implementation.

Under more critical scrutiny there would be a few immediately reconizeable
issues:

\begin{itemize}
  \item In some configurations, accelerators can only perform in ECB mode in
    hardware, limiting both security and performance. To overcome this, the
    accelerator implementation needs to be extended to be more flexible/complex
    and include such operation modes.
  \item Due to the use of generic instruction / RoCC interface, accelerators
    can be exploited by attacker at unprivileged level. To overcome this,
    accelerators and toolchain must be modified to use customized instructions,
    which can be configured for certain privilege levels only.
\end{itemize}

\section{Future work}

As future work, there is much room for improvement; better understanding of how
to leverage the memory coherence hierarchy in the hybrid accelerator model
should lead to better performance; accelerator can be developed further to
accept more encryption modes, including parallelization; security can be
hardened by enforcing privilege levels at the hardware level, to name a few.

Also, a set of different, reutilizable cryptographic primitives can be further
explored and integrated into a larger multi-accelerator framework for
acceleration of other demanded cryptographic functions such as hash functions
and possible compositions of primitives for message authentication, for instance.

These require a more thorough and complex modification of the available
toolchain and datapath microarchitecture, as it is likely that the standard RoCC
interface will not be able to provide the desired flexibility and control
granularity levels for detailed exploration.

\section{Conclusions}

The tools provided by the RISC-V community members enable computer architecture
exploration in a very powerful way. This allowed for the exploration of
different HWACC topologies; we found that there can be performance gains when
using tightly-coupled accelerators and security gains.

In order to achieve maximum performance/security, however, it is necessary to
fully customize the microarchitecture and toolchain to fully orchestrate secure
computations in the CPU's datapath, which will increase development costs.


\bibliography{paper}
\bibliographystyle{ieeetr}

\end{document}